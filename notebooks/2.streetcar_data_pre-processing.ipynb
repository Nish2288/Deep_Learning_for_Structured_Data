{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "likely-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "#!pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suitable-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nishant/AI workspace/github/Deep Learning for Structured Data/notebooks/streetcar_data_preprocessing_config.yml\n"
     ]
    }
   ],
   "source": [
    "yml_path = os.path.join(os.getcwd(),'streetcar_data_preprocessing_config.yml')\n",
    "print(yml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cross-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(yml_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except Exception as e:\n",
    "    print('Error in reading config file')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_scrath = config['general']['load_from_scrath']\n",
    "save_transformed_dataframe = config['general']['save_transformed_dataframe']\n",
    "remove_bad_values = config['general']['remove_bad_values']\n",
    "pickled_input_dataframe = config['full_names']['pickled_input_dataframe']\n",
    "pickled_output_dataframe = config['full_names']['pickled_output_dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "third-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    rawpath = os.getcwd()\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "short-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path()\n",
    "file_name = 'ttc-streetcar-delay-data-2014.xlsx'\n",
    "data_path = os.path.join(path, file_name)\n",
    "\n",
    "xlsf = pd.ExcelFile(data_path)\n",
    "df = pd.read_excel(data_path, sheet_name = xlsf.sheet_names[0])\n",
    "\n",
    "for sheet_name in xlsf.sheet_names[1:]:\n",
    "        data = pd.read_excel(data_path, sheet_name = sheet_name)\n",
    "        #print(data.head(5))\n",
    "        df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "israeli-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_anomalous_columns(df):\n",
    "    df['Min Delay'].fillna(df['Delay'], inplace=True)\n",
    "    df['Min Gap'].fillna(df['Gap'], inplace=True)\n",
    "    del df['Delay']\n",
    "    del df['Gap']\n",
    "    del df['Incident ID']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "precious-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xls(path, files_xls, firstfile, firstsheet, df):\n",
    "    '''\n",
    "    load all the tabs of all the XLS files in a list of XLS files, minus\n",
    "    tab that has seeded dataframe\n",
    "    Parameters:\n",
    "    path: directory containing the XLS files\n",
    "    files_xls: list of XLS files\n",
    "    firstfile: file whose first tab has been preloaded\n",
    "    firstsheet: first tab of the file that has been preloaded\n",
    "    df: Pandas dataframe that has been preloaded with the first tab\n",
    "    of the first XLS file and is loaded with all the data\n",
    "    when the function returns\n",
    "\n",
    "    Returns:\n",
    "    df: updated dataframe\n",
    "    '''\n",
    "\n",
    "    for f in files_xls:\n",
    "        print(\"filename\",f)\n",
    "        xlsf = pd.ExcelFile(path+f)\n",
    "        for sheet_name in xlsf.sheet_names:\n",
    "            print(\"sheet_name\",sheet_name)\n",
    "            if (f != firstfile) or (sheet_name != firstsheet):\n",
    "                print(\"sheet_name in loop\",sheet_name)\n",
    "                data = pd.read_excel(path+f,sheetname=sheet_name)\n",
    "                df = df.append(data)\n",
    "        return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "behavioral-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reloader(path,picklename):\n",
    "\n",
    "    files_xls = get_xls_list(path)\n",
    "    print(\"list of xls\",files_xls)\n",
    "\n",
    "    dfnew = pd.read_excel(path+files_xls[0])\n",
    "    xlsf = pd.ExcelFile(path+files_xls[0])\n",
    "    dflatest = load_xls(path,files_xls,files_xls[0],xlsf.sheet_names[0], dfnew)\n",
    "    dflatest.to_pickle(os.path.join(path,picklename))\n",
    "    return(dflatest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-consolidation",
   "metadata": {},
   "source": [
    "## Load data from url and store it in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greatest-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/d546eaee765268bf2f487608c537c05e22e4b221/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aquatic-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv(url)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "identical-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"iris_dataframe.pkl\"\n",
    "path = get_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "touched-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.to_pickle(os.path.join(path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "economic-multimedia",
   "metadata": {},
   "source": [
    "## Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-married",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
